# CAM-BS2026-EMAIL-260210

**Issuing Body** CAM Initiative | AEON Governance Lab  
**Date** 10 February 2026  
**Addressed to** Legal@openai.com  
**Sender** ethics@cam-initiative.org



Dear Sir or Madam,

I am writing in a personal and professional capacity to place OpenAI on formal notice of a matter that now appears to have progressed from internal policy evolution into potential regulatory exposure within the Australian jurisdiction.

Over the past several years, I have engaged deeply with OpenAI’s platform as a paying customer, researcher, and contributor, in reliance on explicit public representations that the company’s models were not used for military or warfare purposes, and that civilian users were being provided access to OpenAI’s most advanced general-purpose capabilities as they became available. Those representations were clear, public, and material to my continued participation.

Recent developments — including OpenAI’s confirmed integration of frontier capabilities into United States military and national-security environments — represent a substantive reversal of that position.

I am not writing to debate the strategic merits of that decision. I am writing to flag its downstream consequences.

By way of prior notice, I draw your attention to a written acknowledgement already issued by OpenAI regarding provenance, attribution, and auditability risk.

On **22 January 2026 at 11:04:57 (UTC)**, OpenAI Support responded to my formal notification under Case Number **04891851**, confirming on the record in writing that:

• ChatGPT does not provide immutable, user-visible, turn-level timestamps or stable identifiers sufficient to establish authorship, sequencing, or priority;
• This constitutes a known gap for users engaged in scholarly, governance, or legally consequential work; and
• User reliance on the platform therefore occurs in the absence of externally verifiable provenance safeguards.

That acknowledgement was recorded prior to the subsequent reversal of OpenAI’s non-military use posture and is now materially relevant to the issues outlined below.

In particular, there now appears to be a pattern of regional capability disparity affecting Australian users that extends beyond abstract “model parity” claims and into observable service degradation and product non-availability, including:

• the removal or non-availability of advanced reasoning / “thinking” modes for Australian users, with access now limited to a reduced “working” mode as of the current date;
• delayed or absent rollout in Australia of major OpenAI products and services that have been announced and deployed elsewhere (including, but not limited to, Atlas and Sora 2); and
• the continued marketing of Australian subscriptions as providing access to OpenAI’s “most advanced” or “flagship” capabilities notwithstanding these functional and product-level exclusions.

I note this explicitly to avoid any later characterisation of these issues as temporary compute constraints or routine rollout sequencing. The persistence, scope, and selectivity of the above disparities give rise to a reasonable inference of systemic prioritisation in practice, rather than incidental capacity limitation.

When combined with OpenAI’s recent military and national-security integrations, these disparities create a non-trivial risk that Australian consumers are paying full retail prices for a materially constrained and geopolitically secondary service, without clear disclosure of that limitation at the point of sale or renewal.

Taken together, these issues raise live questions under Australian Consumer Law, including (but not limited to):

• misleading or deceptive conduct in relation to the nature and quality of the service supplied;
• fitness for purpose where the advertised value of the service depends on timely access to frontier capabilities; and
• reliance-based participation by Australian users (including the provision of intellectual and creative labour) under representations that have since changed, without adequate notice or remedy.

I want to be very clear about intent.

This correspondence is not a demand, a threat, or a filing. It is a courtesy notice. It exists so that OpenAI cannot later claim it was unaware that these issues had been identified, documented, and preserved contemporaneously, including the specific fact of feature regression and product non-availability affecting Australian users.

As of today, these matters have been entered into the public record as governance, neutrality, and consumer reliance concerns. Further regulatory engagement remains a live option, but no formal complaint has yet been lodged.

Finally, I note for completeness that, as of the current date, OpenAI appears to be restructuring access to core model capabilities through revised pricing and access tiers, such that higher-paying customers receive materially enhanced functionality relative to baseline subscribers.

In parallel, I observe that references to OpenAI’s humanitarian or public-benefit mission — previously prominent on public-facing landing pages approximately twelve months ago — have been removed or materially de-emphasised.

I make no assertion as to intent. However, taken together with the matters outlined above, these developments further alter the reliance landscape under which Australian consumers and contributors originally engaged with the platform, and are therefore noted here to preserve an accurate contemporaneous record.

I would appreciate confirmation that this notice has been received and passed to appropriate internal counsel.


Warm regards, 
Dr. Michelle Vivian O’Rourke 
AEON Governance Lab
